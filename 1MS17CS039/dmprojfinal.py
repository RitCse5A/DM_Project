# -*- coding: utf-8 -*-
"""DMprojFinal_(2).ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1NTRX0DuKwVj7sge_EtmO6iEanP2uqhDw

# Data Mining Project | TOPIC: Linear Regression

---
***IMPORTING REQD. LIBRARIES:***

---
"""

import numpy as np # Library that makes numeric computations easy, specially on arrays.
import pandas as pd  # Helps to structure and clean data for analysis in the form of Dataframes.
import matplotlib.pyplot as plt # for visualisation (like graphs)
import seaborn as sns # for visualisation

from sklearn.model_selection import train_test_split # For splitting the dataset
from sklearn import metrics

"""---
***LOADING DATASET:***

---
"""

from google.colab import files
uploaded = files.upload()

dataframe = pd.read_csv("Real_estate.csv")
#dataframe.drop(dataframe.index[0], inplace=True)
dataframe.head()

"""---
***PREPROCESSING:***

---
"""

dataframe.drop(["X1 transaction date", "X5 latitude",	"X6 longitude"], axis = 1, inplace = True) 
dataframe.head()

dataframe.rename(columns={'No':'Number',
                          'X2 house age':'X1 house age',
                          'X3 distance to the nearest metro station':'X2 distance to the nearest metro station',
                          'X4 number of convenience stores':'X3 number of convenience stores'
                          }, 
                 inplace=True)
dataframe.head(3)

n_rows,n_columns=dataframe.shape

print(f'There are {n_rows} number of rows and {n_columns} columns')

dataframe.dropna(how='any',inplace=True) #to drop if any value in the row has a nan
print("Missing values exist? ", dataframe.isnull().values.any())

boxplot_data = [dataframe['Number'], dataframe['X1 house age'],dataframe['X2 distance to the nearest metro station'],dataframe['X3 number of convenience stores'],dataframe['Y house price of unit area']]
plt.boxplot(boxplot_data,vert=0, patch_artist=True)

"""---
***LINEAR REGRESSION :***

---

> What the Linear Regression technique does is, it finds the best possible line which fits that training set and then predicts the price of any unseen house (i.e. which was not in the training set).
"""

def plotFeatures(col_list,title):
    plt.figure(figsize=(17, 24))
    i = 0
    print(len(col_list))
    for col in col_list:
        i+=1
        plt.subplot(7,2,i)
        plt.plot(dataframe[col],dataframe["Y house price of unit area"],marker='.',linestyle='none')
        plt.title(title % (col))   
        plt.tight_layout()

colnames = ['X1 house age', 'X2 distance to the nearest metro station', 'X3 number of convenience stores']
plotFeatures(colnames,"Relationship bw %s and 'house price of unit area'")

#Divide the data into independent and dependent variables
x = pd.DataFrame(dataframe["X1 house age"])
y = pd.DataFrame(dataframe["Y house price of unit area"])

# Split the data into train and test sets
X_train, X_test, Y_train, Y_test = train_test_split(x,y, test_size = 0.2, random_state = 1)

# Shape of the train and test sets
print(X_train.shape)
print(X_test.shape)
print(Y_train.shape)
print(Y_test.shape)

"""***-> Using sklearn linear model for Linear Regression***"""

from sklearn.linear_model import LinearRegression
from sklearn import preprocessing

def linear_model_main(X_parameters,Y_parameters,predict_value):
 
    # Create linear regression object
    regr = LinearRegression()
    regr.fit(X_parameters, Y_parameters)
    predict_outcome = regr.predict(predict_value)
    predictions = {}
    predictions['intercept'] = regr.intercept_
    predictions['coefficient'] = regr.coef_
    predictions['predicted_value'] = predict_outcome
    return predictions

result = linear_model_main(X_train,Y_train,X_test)

print("Intercept value: " , result['intercept'])
print("coefficient:" , result['coefficient'])
print("Avg Predicted value: ",np.mean(result['predicted_value']))
print("Avg Actual value: ",np.mean(Y_test))

Y_pred = result['predicted_value']
print(Y_pred)

def show_linear_line(X_parameters,Y_parameters):
    # Create linear regression object
    regr = LinearRegression()
    regr.fit(X_parameters, Y_parameters)
    plt.scatter(X_parameters,Y_parameters,color='blue')
    plt.plot(X_parameters,regr.predict(X_parameters),color='red',linewidth=4)
    plt.xticks(())
    plt.yticks(())
    plt.show()

show_linear_line(X_train, Y_train) #Best Fitting Line

print(Y_pred.shape)
print(Y_test.shape)

# Actual value
Y_test = np.asarray(Y_test).T
#print(Y_test)
Y_act_pred = pd.DataFrame({'Actual Y':list(Y_test), 'Predicted Y:':list(Y_pred)})
Y_act_pred

# Evaluate the algorithm
print('Mean Absolute Error: ', metrics.mean_absolute_error(Y_test, Y_pred))
print('Mean Squared Error: ', metrics.mean_squared_error(Y_test, Y_pred))
print('Root Mean Squared Error: ', np.sqrt(metrics.mean_squared_error(Y_test, Y_pred)))